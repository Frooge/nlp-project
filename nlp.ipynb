{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "from gensim import corpora\n",
    "import re\n",
    "import spacy\n",
    "import pyLDAvis\n",
    "import pyLDAvis.gensim #dont skip this\n",
    "from wordcloud import WordCloud\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to C:\\Users\\Jade\n",
      "[nltk_data]     Rosales\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Download NLTK resources if you haven't already\n",
    "nltk.download('punkt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:15: DeprecationWarning: invalid escape sequence '\\['\n",
      "<>:16: DeprecationWarning: invalid escape sequence '\\S'\n",
      "<>:19: DeprecationWarning: invalid escape sequence '\\w'\n",
      "<>:15: DeprecationWarning: invalid escape sequence '\\['\n",
      "<>:16: DeprecationWarning: invalid escape sequence '\\S'\n",
      "<>:19: DeprecationWarning: invalid escape sequence '\\w'\n",
      "C:\\Users\\Jade Rosales\\AppData\\Local\\Temp\\ipykernel_15456\\3971950116.py:15: DeprecationWarning: invalid escape sequence '\\['\n",
      "  text = re.sub('\\[.*?\\]', '', text)\n",
      "C:\\Users\\Jade Rosales\\AppData\\Local\\Temp\\ipykernel_15456\\3971950116.py:16: DeprecationWarning: invalid escape sequence '\\S'\n",
      "  text = re.sub('https?://\\S+|www\\.\\S+', '', text)\n",
      "C:\\Users\\Jade Rosales\\AppData\\Local\\Temp\\ipykernel_15456\\3971950116.py:19: DeprecationWarning: invalid escape sequence '\\w'\n",
      "  text = re.sub('\\w*\\d\\w*', '', text)\n"
     ]
    }
   ],
   "source": [
    "def filter_spoiler_reviews(df):\n",
    "    return df.drop(df[df['review'] == '[SPOILER ALERT: This review contains spoilers.]'].index)\n",
    "\n",
    "# Function to categorize the ratings\n",
    "def categorize_rating(rating):\n",
    "    if rating <= 5:\n",
    "        return  'Negative Review'\n",
    "    else:\n",
    "        return 'Positive Review'\n",
    "    \n",
    "def clean_text(text):\n",
    "    '''Make text lowercase, remove text in square brackets,remove links,remove punctuation\n",
    "    and remove words containing numbers.'''\n",
    "    text = str(text).lower()\n",
    "    text = re.sub('\\[.*?\\]', '', text)\n",
    "    text = re.sub('https?://\\S+|www\\.\\S+', '', text)\n",
    "    text = re.sub('<.*?>+', '', text)\n",
    "    text = re.sub('\\n', '', text)\n",
    "    text = re.sub('\\w*\\d\\w*', '', text)\n",
    "    return text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "game_df = {}\n",
    "\n",
    "def process_df(df, filenames):\n",
    "    df = pd.concat([pd.read_csv(filename) for filename in filenames])\n",
    "    df = filter_spoiler_reviews(df)\n",
    "    df['rating'] = df['rating'].apply(categorize_rating)\n",
    "    df['review'] = df['review'].apply(clean_text)\n",
    "    return df\n",
    "\n",
    "filenames_dict = {\n",
    "    'engage': ['dataset/engage.csv'],\n",
    "    'threehouses': ['dataset/threehouses.csv'],\n",
    "    'echoes': ['dataset/echoes.csv'],\n",
    "    'conquest': ['dataset/conquest.csv'],\n",
    "    'birthright': ['dataset/revelations.csv'],\n",
    "    'revelations': ['dataset/birthrite.csv'],\n",
    "    'awakening': ['dataset/awakening.csv'],\n",
    "}\n",
    "\n",
    "for df_name, filenames in filenames_dict.items():\n",
    "    game_df[df_name] = process_df(pd.DataFrame(), filenames)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "negative_reviews_dict = {}\n",
    "positive_reviews_dict = {}\n",
    "\n",
    "for df_name, df in game_df.items():\n",
    "    negative_reviews_dict[df_name] = df[df['rating'] == 'Negative Review']\n",
    "    positive_reviews_dict[df_name] = df[df['rating'] == 'Positive Review']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall\n",
      "2045\n",
      "engage\n",
      "Total Reviews:  468\n",
      "Negative Reviews:  170\n",
      "Positive Reviews:  298\n",
      "threehouses\n",
      "Total Reviews:  987\n",
      "Negative Reviews:  82\n",
      "Positive Reviews:  905\n",
      "echoes\n",
      "Total Reviews:  95\n",
      "Negative Reviews:  8\n",
      "Positive Reviews:  87\n",
      "conquest\n",
      "Total Reviews:  47\n",
      "Negative Reviews:  9\n",
      "Positive Reviews:  38\n",
      "birthright\n",
      "Total Reviews:  34\n",
      "Negative Reviews:  8\n",
      "Positive Reviews:  26\n",
      "revelations\n",
      "Total Reviews:  76\n",
      "Negative Reviews:  12\n",
      "Positive Reviews:  64\n",
      "awakening\n",
      "Total Reviews:  338\n",
      "Negative Reviews:  21\n",
      "Positive Reviews:  317\n"
     ]
    }
   ],
   "source": [
    "total=0\n",
    "print('Overall')\n",
    "for attr, df in game_df.items():  # Assuming game_df is a dictionary\n",
    "    total += len(df)\n",
    "\n",
    "print(total)\n",
    "\n",
    "for attr, df in game_df.items():\n",
    "    print(attr)\n",
    "    print('Total Reviews: ',len(df))\n",
    "    print('Negative Reviews: ',len(negative_reviews_dict[attr]))\n",
    "    print('Positive Reviews: ',len(positive_reviews_dict[attr]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import opinion_lexicon\n",
    "\n",
    "# # Initialize positive and negative word sets\n",
    "positive_words = set(opinion_lexicon.positive())\n",
    "negative_words = set(opinion_lexicon.negative())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from gensim.models.keyedvectors import KeyedVectors\n",
    "\n",
    "# path='GoogleNews-vectors-negative300.bin.gz'\n",
    "# model = KeyedVectors.load_word2vec_format(path, binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.utils import simple_preprocess\n",
    "\n",
    "# words_to_check = ['gameplay', 'objectives', 'story', 'aesthetics', 'strategy', 'constraints', 'fun',  'boring', 'interactive', 'music', 'audio', 'challenge', 'reward', 'graphics', 'animation', 'level', 'design', 'character', 'challenge', 'theme', 'creative', 'feature', 'style', 'emotional', 'memorable', 'personality', 'map', 'world', 'development']\n",
    "\n",
    "# similar_words = []\n",
    "# for word in words_to_check:\n",
    "#     similar_words.append(model.most_similar(word, topn=10))\n",
    "\n",
    "# similar_words_list = [item[0] for sublist in similar_words for item in sublist]\n",
    "\n",
    "# similar_words_list.extend(words_to_check)\n",
    "\n",
    "nlp = spacy.load('en_core_web_sm', disable=['parser','ner'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i',\n",
       " 'me',\n",
       " 'my',\n",
       " 'myself',\n",
       " 'we',\n",
       " 'our',\n",
       " 'ours',\n",
       " 'ourselves',\n",
       " 'you',\n",
       " \"you're\",\n",
       " \"you've\",\n",
       " \"you'll\",\n",
       " \"you'd\",\n",
       " 'your',\n",
       " 'yours',\n",
       " 'yourself',\n",
       " 'yourselves',\n",
       " 'he',\n",
       " 'him',\n",
       " 'his',\n",
       " 'himself',\n",
       " 'she',\n",
       " \"she's\",\n",
       " 'her',\n",
       " 'hers',\n",
       " 'herself',\n",
       " 'it',\n",
       " \"it's\",\n",
       " 'its',\n",
       " 'itself',\n",
       " 'they',\n",
       " 'them',\n",
       " 'their',\n",
       " 'theirs',\n",
       " 'themselves',\n",
       " 'what',\n",
       " 'which',\n",
       " 'who',\n",
       " 'whom',\n",
       " 'this',\n",
       " 'that',\n",
       " \"that'll\",\n",
       " 'these',\n",
       " 'those',\n",
       " 'am',\n",
       " 'is',\n",
       " 'are',\n",
       " 'was',\n",
       " 'were',\n",
       " 'be',\n",
       " 'been',\n",
       " 'being',\n",
       " 'have',\n",
       " 'has',\n",
       " 'had',\n",
       " 'having',\n",
       " 'do',\n",
       " 'does',\n",
       " 'did',\n",
       " 'doing',\n",
       " 'a',\n",
       " 'an',\n",
       " 'the',\n",
       " 'and',\n",
       " 'but',\n",
       " 'if',\n",
       " 'or',\n",
       " 'because',\n",
       " 'as',\n",
       " 'until',\n",
       " 'while',\n",
       " 'of',\n",
       " 'at',\n",
       " 'by',\n",
       " 'for',\n",
       " 'with',\n",
       " 'about',\n",
       " 'against',\n",
       " 'between',\n",
       " 'into',\n",
       " 'through',\n",
       " 'during',\n",
       " 'before',\n",
       " 'after',\n",
       " 'above',\n",
       " 'below',\n",
       " 'to',\n",
       " 'from',\n",
       " 'up',\n",
       " 'down',\n",
       " 'in',\n",
       " 'out',\n",
       " 'on',\n",
       " 'off',\n",
       " 'over',\n",
       " 'under',\n",
       " 'again',\n",
       " 'further',\n",
       " 'then',\n",
       " 'once',\n",
       " 'here',\n",
       " 'there',\n",
       " 'when',\n",
       " 'where',\n",
       " 'why',\n",
       " 'how',\n",
       " 'all',\n",
       " 'any',\n",
       " 'both',\n",
       " 'each',\n",
       " 'few',\n",
       " 'more',\n",
       " 'most',\n",
       " 'other',\n",
       " 'some',\n",
       " 'such',\n",
       " 'no',\n",
       " 'nor',\n",
       " 'not',\n",
       " 'only',\n",
       " 'own',\n",
       " 'same',\n",
       " 'so',\n",
       " 'than',\n",
       " 'too',\n",
       " 'very',\n",
       " 's',\n",
       " 't',\n",
       " 'can',\n",
       " 'will',\n",
       " 'just',\n",
       " 'don',\n",
       " \"don't\",\n",
       " 'should',\n",
       " \"should've\",\n",
       " 'now',\n",
       " 'd',\n",
       " 'll',\n",
       " 'm',\n",
       " 'o',\n",
       " 're',\n",
       " 've',\n",
       " 'y',\n",
       " 'ain',\n",
       " 'aren',\n",
       " \"aren't\",\n",
       " 'couldn',\n",
       " \"couldn't\",\n",
       " 'didn',\n",
       " \"didn't\",\n",
       " 'doesn',\n",
       " \"doesn't\",\n",
       " 'hadn',\n",
       " \"hadn't\",\n",
       " 'hasn',\n",
       " \"hasn't\",\n",
       " 'haven',\n",
       " \"haven't\",\n",
       " 'isn',\n",
       " \"isn't\",\n",
       " 'ma',\n",
       " 'mightn',\n",
       " \"mightn't\",\n",
       " 'mustn',\n",
       " \"mustn't\",\n",
       " 'needn',\n",
       " \"needn't\",\n",
       " 'shan',\n",
       " \"shan't\",\n",
       " 'shouldn',\n",
       " \"shouldn't\",\n",
       " 'wasn',\n",
       " \"wasn't\",\n",
       " 'weren',\n",
       " \"weren't\",\n",
       " 'won',\n",
       " \"won't\",\n",
       " 'wouldn',\n",
       " \"wouldn't\",\n",
       " '!',\n",
       " '\"',\n",
       " '#',\n",
       " '$',\n",
       " '%',\n",
       " '&',\n",
       " \"'\",\n",
       " '(',\n",
       " ')',\n",
       " '*',\n",
       " '+',\n",
       " ',',\n",
       " '-',\n",
       " '.',\n",
       " '/',\n",
       " ':',\n",
       " ';',\n",
       " '<',\n",
       " '=',\n",
       " '>',\n",
       " '?',\n",
       " '@',\n",
       " '[',\n",
       " '\\\\',\n",
       " ']',\n",
       " '^',\n",
       " '_',\n",
       " '`',\n",
       " '{',\n",
       " '|',\n",
       " '}',\n",
       " '~',\n",
       " 'fire',\n",
       " 'emblem',\n",
       " 'game',\n",
       " 'awakening',\n",
       " 'conquest',\n",
       " 'fate',\n",
       " 'birthright',\n",
       " 'revelations',\n",
       " 'echo',\n",
       " 'shadow',\n",
       " 'valentia',\n",
       " 'three',\n",
       " 'house',\n",
       " 'engage',\n",
       " 'play',\n",
       " 'buy',\n",
       " 'rpg']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#nlp stopwords\n",
    "import string\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "stop_words= stopwords.words('english') + list(string.punctuation)\n",
    "stop_words += list(['fire', 'emblem', 'game','awakening', 'conquest', 'fate', 'birthright', 'revelations', 'echo', 'shadow', 'valentia' ,'three', 'house', 'engage', 'play', 'buy', 'rpg'])\n",
    "stop_words\n",
    "\n",
    "# spacy.lang.en.stop_words.STOP_WORDS |= {'fire', 'emblem'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.corpora import Dictionary\n",
    "from gensim.models import LdaModel\n",
    "from gensim.models import TfidfModel\n",
    "from gensim.models import CoherenceModel\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from gensim.models import Phrases\n",
    "from gensim.models.phrases import Phraser\n",
    "from gensim.models.ldamulticore import LdaMulticore\n",
    "from gensim.models import LsiModel\n",
    "\n",
    "snow_stemmer = SnowballStemmer(language='english')\n",
    "\n",
    "\n",
    "def lemmatization(texts,allowed_postags=['NOUN','ADJ','VERB','ADV']):\n",
    "    \"\"\"https://spacy.io/api/annotation\"\"\"\n",
    "    data_words=simple_preprocess(str(texts))\n",
    "    doc=nlp(' '.join(data_words))\n",
    "    tokens = [token.lemma_ for token in doc if token.pos_ in allowed_postags]\n",
    "    tokens = [word for word in tokens if word not in stop_words]\n",
    "    tokens = [word for word in tokens if word not in positive_words]\n",
    "    tokens = [word for word in tokens if word not in negative_words]\n",
    "    # tokens = [snow_stemmer.stem(token) for token in tokens]\n",
    "\n",
    "    # gram_tokens = nltk.bigrams(tokens)\n",
    "    # stemmed_grams = ['_'.join(gram) for gram in gram_tokens]\n",
    "    # tokens = stemmed_tokens+stemmed_grams\n",
    "    return tokens\n",
    "\n",
    "def create_corpus(df):\n",
    "    # Tokenize the 'Review' column\n",
    "    tokenized_reviews = df['review'].apply(lemmatization, allowed_postags=['NOUN'])\n",
    "\n",
    "    # Add n-grams\n",
    "    phrases = Phrases(tokenized_reviews, min_count=5, threshold=100)\n",
    "    bigram = Phraser(phrases)\n",
    "    tokenized_reviews = list(bigram[tokenized_reviews])\n",
    "\n",
    "    dictionary = Dictionary(tokenized_reviews)\n",
    "\n",
    "    corpus = [dictionary.doc2bow(text) for text in tokenized_reviews]\n",
    "\n",
    "    return (corpus, dictionary, tokenized_reviews)\n",
    "\n",
    "def calc_coherence_values(dictionary, corpus, texts, num_topics=10):\n",
    "    # Train a LDA model\n",
    "    model = LdaMulticore(corpus=corpus,id2word = dictionary, num_topics = num_topics, alpha=.1, eta=0.1, random_state = 42)\n",
    "    print('model created')\n",
    "    \n",
    "    # Calculate for the coherence score\n",
    "    coherencemodel = CoherenceModel(model = model, texts = texts, dictionary = dictionary, coherence = 'c_v')\n",
    "    coherence_value = coherencemodel.get_coherence()\n",
    "    return model, coherence_value\n",
    "\n",
    "\n",
    "def tfidf(corpus, dictionary):\n",
    "    # Train a TF-IDF model\n",
    "    tfidf = TfidfModel(corpus=corpus)\n",
    "\n",
    "    # Get TF-IDF weights for each word\n",
    "    tfidf_corpus = tfidf[corpus]\n",
    "\n",
    "    # Sort the words by their TF-IDF weights\n",
    "    words = sorted([(dictionary[word_id], weight) for doc in tfidf_corpus for word_id, weight in doc], key=lambda x: -x[1])\n",
    "\n",
    "\n",
    "    return tfidf_corpus, words\n",
    "      \n",
    "\n",
    "def display_frequent_words(words):\n",
    "    seen_words = set()\n",
    "    for word, weight in words:\n",
    "        if word not in seen_words:\n",
    "            print(f\"{word}: {weight}\")\n",
    "            seen_words.add(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for engage\n",
      "model created\n"
     ]
    }
   ],
   "source": [
    "for attr, value in negative_reviews_dict.items():\n",
    "    print('Results for ' + attr)\n",
    "    corpus, dict, token = create_corpus(value)\n",
    "    tfidf_corpus, words = tfidf(corpus, dict)\n",
    "    lda_model, coherence_value = calc_coherence_values(dictionary = dict, corpus = tfidf_corpus, texts = token, num_topics=25)\n",
    "    print(coherence_value)\n",
    "    pyLDAvis.enable_notebook()\n",
    "    vis=pyLDAvis.gensim.prepare(lda_model,corpus,dict,mds='mmds')\n",
    "    pyLDAvis.save_html(vis, 'results/'+attr+'_negative.html')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for Unnamed: 0\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'review'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\Jade Rosales\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3652\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3651\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3652\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3653\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32mc:\\Users\\Jade Rosales\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\_libs\\index.pyx:147\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\Jade Rosales\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\_libs\\index.pyx:155\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\index_class_helper.pxi:70\u001b[0m, in \u001b[0;36mpandas._libs.index.Int64Engine._check_type\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'review'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[31], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m attr, value \u001b[38;5;129;01min\u001b[39;00m positive_reviews_dict\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m      2\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mResults for \u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m attr)\n\u001b[1;32m----> 3\u001b[0m     corpus, \u001b[38;5;28mdict\u001b[39m, token \u001b[38;5;241m=\u001b[39m \u001b[43mcreate_corpus\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      4\u001b[0m     tfidf_corpus, words \u001b[38;5;241m=\u001b[39m tfidf(corpus, \u001b[38;5;28mdict\u001b[39m)\n\u001b[0;32m      5\u001b[0m     lda_model, coherence_value \u001b[38;5;241m=\u001b[39m calc_coherence_values(dictionary \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m, corpus \u001b[38;5;241m=\u001b[39m tfidf_corpus, texts \u001b[38;5;241m=\u001b[39m token, num_topics\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m25\u001b[39m)\n",
      "Cell \u001b[1;32mIn[19], line 31\u001b[0m, in \u001b[0;36mcreate_corpus\u001b[1;34m(df)\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreate_corpus\u001b[39m(df):\n\u001b[0;32m     30\u001b[0m     \u001b[38;5;66;03m# Tokenize the 'Review' column\u001b[39;00m\n\u001b[1;32m---> 31\u001b[0m     tokenized_reviews \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mreview\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mapply(lemmatization, allowed_postags\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNOUN\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m     33\u001b[0m     \u001b[38;5;66;03m# Add n-grams\u001b[39;00m\n\u001b[0;32m     34\u001b[0m     phrases \u001b[38;5;241m=\u001b[39m Phrases(tokenized_reviews, min_count\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m, threshold\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\Jade Rosales\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\series.py:1012\u001b[0m, in \u001b[0;36mSeries.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   1009\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values[key]\n\u001b[0;32m   1011\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m key_is_scalar:\n\u001b[1;32m-> 1012\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_value\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1014\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_hashable(key):\n\u001b[0;32m   1015\u001b[0m     \u001b[38;5;66;03m# Otherwise index.get_value will raise InvalidIndexError\u001b[39;00m\n\u001b[0;32m   1016\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1017\u001b[0m         \u001b[38;5;66;03m# For labels that don't resolve as scalars like tuples and frozensets\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Jade Rosales\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\series.py:1121\u001b[0m, in \u001b[0;36mSeries._get_value\u001b[1;34m(self, label, takeable)\u001b[0m\n\u001b[0;32m   1118\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values[label]\n\u001b[0;32m   1120\u001b[0m \u001b[38;5;66;03m# Similar to Index.get_value, but we do not fall back to positional\u001b[39;00m\n\u001b[1;32m-> 1121\u001b[0m loc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1123\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(loc):\n\u001b[0;32m   1124\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values[loc]\n",
      "File \u001b[1;32mc:\\Users\\Jade Rosales\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3654\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3652\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[0;32m   3653\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m-> 3654\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   3655\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m   3656\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3657\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3658\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3659\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'review'"
     ]
    }
   ],
   "source": [
    "for attr, value in positive_reviews_dict.items():\n",
    "    print('Results for ' + attr)\n",
    "    corpus, dict, token = create_corpus(value)\n",
    "    tfidf_corpus, words = tfidf(corpus, dict)\n",
    "    lda_model, coherence_value = calc_coherence_values(dictionary = dict, corpus = tfidf_corpus, texts = token, num_topics=25)\n",
    "    print(coherence_value)\n",
    "    pyLDAvis.enable_notebook()\n",
    "    vis=pyLDAvis.gensim.prepare(lda_model,corpus,dict,mds='mmds')\n",
    "    pyLDAvis.save_html(vis, 'results/'+attr+'_positive.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_df = pd.concat(game_df.values(), ignore_index=True)\n",
    "negative_reviews_dict = all_df[all_df['rating'] == 'Negative Review']\n",
    "positive_reviews_dict = all_df[all_df['rating'] == 'Positive Review']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for negative overall\n"
     ]
    }
   ],
   "source": [
    "print('Results for negative overall')\n",
    "corpus, dict, token = create_corpus(all_df)\n",
    "token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model created\n",
      "0.5718206735668736\n"
     ]
    }
   ],
   "source": [
    "tfidf_corpus, words = tfidf(corpus, dict)\n",
    "lda_model, coherence_value = calc_coherence_values(dictionary = dict, corpus = tfidf_corpus, texts = token, num_topics=25)\n",
    "print(coherence_value)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic: 0 \n",
      "Words: 0.008*\"character\" + 0.008*\"strategy\" + 0.006*\"story\" + 0.006*\"route\" + 0.005*\"map\" + 0.005*\"battle\" + 0.005*\"time\" + 0.004*\"series\" + 0.004*\"graphic\" + 0.004*\"title\"\n",
      "Topic: 1 \n",
      "Words: 0.005*\"lot\" + 0.005*\"year\" + 0.005*\"ability\" + 0.005*\"replayability\" + 0.005*\"replay\" + 0.004*\"route\" + 0.004*\"fan\" + 0.004*\"story\" + 0.004*\"character\" + 0.004*\"gameplay\"\n",
      "Topic: 2 \n",
      "Words: 0.008*\"gameplay\" + 0.008*\"story\" + 0.007*\"character\" + 0.007*\"people\" + 0.006*\"switch\" + 0.006*\"series\" + 0.005*\"battle\" + 0.005*\"hour\" + 0.005*\"mechanic\" + 0.004*\"nintendo\"\n",
      "Topic: 3 \n",
      "Words: 0.007*\"switch\" + 0.006*\"story\" + 0.006*\"battle\" + 0.005*\"route\" + 0.005*\"character\" + 0.005*\"hour\" + 0.005*\"time\" + 0.005*\"part\" + 0.005*\"gameplay\" + 0.004*\"combat\"\n",
      "Topic: 4 \n",
      "Words: 0.007*\"character\" + 0.006*\"gameplay\" + 0.005*\"series\" + 0.005*\"one\" + 0.005*\"level\" + 0.005*\"story\" + 0.004*\"mechanic\" + 0.004*\"music\" + 0.004*\"switch\" + 0.004*\"graphic\"\n",
      "Topic: 5 \n",
      "Words: 0.009*\"character\" + 0.008*\"series\" + 0.005*\"story\" + 0.005*\"music\" + 0.005*\"year\" + 0.004*\"feature\" + 0.004*\"time\" + 0.004*\"battle\" + 0.004*\"mechanic\" + 0.004*\"thing\"\n",
      "Topic: 6 \n",
      "Words: 0.005*\"mechanic\" + 0.005*\"character\" + 0.005*\"hour\" + 0.004*\"battle\" + 0.004*\"gameplay\" + 0.004*\"lot\" + 0.004*\"story\" + 0.004*\"couple\" + 0.004*\"franchise\" + 0.004*\"route\"\n",
      "Topic: 7 \n",
      "Words: 0.008*\"lot\" + 0.007*\"story\" + 0.007*\"gameplay\" + 0.007*\"character\" + 0.005*\"system\" + 0.004*\"graphic\" + 0.004*\"combat\" + 0.004*\"unit\" + 0.004*\"way\" + 0.004*\"series\"\n",
      "Topic: 8 \n",
      "Words: 0.009*\"switch\" + 0.009*\"story\" + 0.007*\"character\" + 0.007*\"hour\" + 0.007*\"mechanic\" + 0.006*\"gameplay\" + 0.006*\"music\" + 0.005*\"time\" + 0.004*\"series\" + 0.004*\"combat\"\n",
      "Topic: 9 \n",
      "Words: 0.006*\"fan\" + 0.006*\"character\" + 0.006*\"story\" + 0.006*\"heart\" + 0.006*\"gameplay\" + 0.005*\"route\" + 0.005*\"series\" + 0.005*\"playthrough\" + 0.005*\"ton\" + 0.005*\"battle\"\n",
      "Topic: 10 \n",
      "Words: 0.006*\"series\" + 0.006*\"strategy\" + 0.006*\"story\" + 0.005*\"thing\" + 0.005*\"fan\" + 0.005*\"lot\" + 0.005*\"character\" + 0.004*\"mechanic\" + 0.004*\"gameplay\" + 0.004*\"time\"\n",
      "Topic: 11 \n",
      "Words: 0.007*\"review\" + 0.005*\"character\" + 0.005*\"series\" + 0.005*\"time\" + 0.005*\"graphic\" + 0.004*\"system\" + 0.004*\"lot\" + 0.004*\"combat\" + 0.004*\"bit\" + 0.004*\"story\"\n",
      "Topic: 12 \n",
      "Words: 0.012*\"story\" + 0.010*\"character\" + 0.009*\"strategy\" + 0.009*\"gameplay\" + 0.008*\"hour\" + 0.007*\"time\" + 0.006*\"lot\" + 0.005*\"thing\" + 0.005*\"graphic\" + 0.004*\"review\"\n",
      "Topic: 13 \n",
      "Words: 0.010*\"story\" + 0.010*\"time\" + 0.009*\"combat\" + 0.006*\"people\" + 0.006*\"character\" + 0.006*\"review\" + 0.005*\"gameplay\" + 0.005*\"system\" + 0.005*\"hour\" + 0.004*\"series\"\n",
      "Topic: 14 \n",
      "Words: 0.010*\"system\" + 0.007*\"story\" + 0.006*\"character\" + 0.006*\"fan\" + 0.005*\"gameplay\" + 0.005*\"dlc\" + 0.005*\"mode\" + 0.005*\"series\" + 0.004*\"weapon\" + 0.004*\"graphic\"\n",
      "Topic: 15 \n",
      "Words: 0.005*\"character\" + 0.005*\"story\" + 0.004*\"gameplay\" + 0.004*\"map\" + 0.004*\"class\" + 0.004*\"system\" + 0.003*\"time\" + 0.003*\"fan\" + 0.003*\"replay_value\" + 0.003*\"ending\"\n",
      "Topic: 16 \n",
      "Words: 0.006*\"combat\" + 0.006*\"title\" + 0.006*\"character\" + 0.005*\"part\" + 0.005*\"battle\" + 0.005*\"story\" + 0.004*\"time\" + 0.004*\"franchise\" + 0.003*\"lot\" + 0.003*\"gameplay\"\n",
      "Topic: 17 \n",
      "Words: 0.005*\"character\" + 0.004*\"relationship\" + 0.004*\"graphic\" + 0.003*\"buen\" + 0.003*\"path\" + 0.003*\"life\" + 0.003*\"story\" + 0.003*\"series\" + 0.003*\"mechanic\" + 0.003*\"strategy\"\n",
      "Topic: 18 \n",
      "Words: 0.006*\"character\" + 0.005*\"design\" + 0.005*\"story\" + 0.004*\"music\" + 0.004*\"mejor\" + 0.003*\"lot\" + 0.003*\"strategy\" + 0.003*\"unit\" + 0.003*\"term\" + 0.003*\"experience\"\n",
      "Topic: 19 \n",
      "Words: 0.005*\"character\" + 0.005*\"hour\" + 0.005*\"story\" + 0.005*\"saga\" + 0.004*\"one\" + 0.004*\"gameplay\" + 0.004*\"lot\" + 0.004*\"amount\" + 0.003*\"bit\" + 0.003*\"fan\"\n",
      "Topic: 20 \n",
      "Words: 0.012*\"gameplay\" + 0.010*\"series\" + 0.008*\"story\" + 0.006*\"character\" + 0.006*\"graphic\" + 0.005*\"design\" + 0.005*\"soundtrack\" + 0.004*\"lore\" + 0.004*\"art\" + 0.004*\"version\"\n",
      "Topic: 21 \n",
      "Words: 0.006*\"system\" + 0.006*\"series\" + 0.006*\"character\" + 0.006*\"music\" + 0.005*\"story\" + 0.004*\"strategy\" + 0.004*\"gameplay\" + 0.004*\"fan\" + 0.004*\"battle\" + 0.004*\"cast\"\n",
      "Topic: 22 \n",
      "Words: 0.011*\"time\" + 0.007*\"character\" + 0.005*\"story\" + 0.005*\"music\" + 0.005*\"gameplay\" + 0.005*\"map\" + 0.005*\"battle\" + 0.004*\"mechanic\" + 0.004*\"content\" + 0.004*\"fan\"\n",
      "Topic: 23 \n",
      "Words: 0.011*\"character\" + 0.009*\"story\" + 0.008*\"gameplay\" + 0.007*\"strategy\" + 0.005*\"time\" + 0.005*\"world\" + 0.005*\"hour\" + 0.004*\"switch\" + 0.004*\"review\" + 0.004*\"history\"\n",
      "Topic: 24 \n",
      "Words: 0.007*\"gameplay\" + 0.006*\"story\" + 0.006*\"character\" + 0.005*\"route\" + 0.005*\"music\" + 0.004*\"mejor\" + 0.004*\"experience\" + 0.004*\"development\" + 0.003*\"mechanic\" + 0.003*\"thing\"\n"
     ]
    }
   ],
   "source": [
    "for idx, topic in lda_model.print_topics(-1):\n",
    "    print(f'Topic: {idx} \\nWords: {topic}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Jade Rosales\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\manifold\\_mds.py:298: FutureWarning: The default value of `normalized_stress` will change to `'auto'` in version 1.4. To suppress this warning, manually set the value of `normalized_stress`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "pyLDAvis.enable_notebook()\n",
    "vis=pyLDAvis.gensim.prepare(lda_model,corpus,dict,mds='mmds')\n",
    "pyLDAvis.save_html(vis, 'results/all_negative.html')\n",
    "vis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Results for positive overall')\n",
    "corpus, dict, token = create_corpus(all_df)\n",
    "token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_corpus, words = tfidf(corpus, dict)\n",
    "lda_model, coherence_value = calc_coherence_values(dictionary = dict, corpus = tfidf_corpus, texts = token, num_topics=25)\n",
    "print(coherence_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, topic in lda_model.print_topics(-1):\n",
    "    print(f'Topic: {idx} \\nWords: {topic}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pyLDAvis.enable_notebook()\n",
    "vis=pyLDAvis.gensim.prepare(lda_model,corpus,dict,mds='mmds')\n",
    "pyLDAvis.save_html(vis, 'results/all_positive.html')\n",
    "vis"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
